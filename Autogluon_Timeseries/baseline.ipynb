{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6571c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luca\\miniconda3\\envs\\FairTS\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "\n",
    "from metrics import MAPE_GroupFairnessScorer, evaluate_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13797c1",
   "metadata": {},
   "source": [
    "Look into autogluon tutorial for explanations of this code  \n",
    "The dtype of the columns determines the interpretation and preprocessing of the features  \n",
    "Autogluon has its own dataframe type with static and dynamic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9638eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sorting the dataframe index before generating the train/test split.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"possible_datasets/M4/train.csv\")\n",
    "static_features_df = pd.read_csv(\"possible_datasets/M4/metadata.csv\")\n",
    "\n",
    "WEEKEND_INDICES = [5, 6]\n",
    "df[\"weekend\"] = pd.DatetimeIndex(df[\"timestamp\"].astype('datetime64[ns]').values).weekday.isin(WEEKEND_INDICES)\n",
    "\n",
    "train_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    df,\n",
    "    id_column=\"item_id\",\n",
    "    timestamp_column=\"timestamp\",\n",
    "    static_features_df=static_features_df,\n",
    ")\n",
    "\n",
    "PREDICTION_LENGTH = 14\n",
    "train_data, test_data = train_data.train_test_split(PREDICTION_LENGTH)      #split seems to be done stratified with respect to the static features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fa0319",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a443a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'c:\\Users\\Luca\\Studium\\Master\\Master-project\\AutogluonModels\\ag-20251128_104047'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          4\n",
      "GPU Count:          0\n",
      "Memory Avail:       0.72 GB / 7.88 GB (9.1%)\n",
      "Disk Space Avail:   81.38 GB / 475.69 GB (17.1%)\n",
      "===================================================\n",
      "Setting presets to: fast_training\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'hyperparameters': 'very_light',\n",
      " 'known_covariates_names': ['weekend'],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 14,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'target',\n",
      " 'verbosity': 2}\n",
      "\n",
      "Inferred time series frequency: 'D'\n",
      "Provided train_data has 243060 rows, 100 time series. Median time series length is 3180 (min=101, max=4301). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'target'\n",
      "\tknown_covariates:\n",
      "\t\tcategorical:        []\n",
      "\t\tcontinuous (float): ['weekend']\n",
      "\tstatic_features:\n",
      "\t\tcategorical:        ['domain']\n",
      "\t\tcontinuous (float): []\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-11-28 11:40:55\n",
      "Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta']\n",
      "Training timeseries model Naive. \n",
      "\t-0.0202       = Validation score (-WQL)\n",
      "\t0.22    s     = Training runtime\n",
      "\t12.22   s     = Validation (prediction) runtime\n",
      "Training timeseries model SeasonalNaive. \n",
      "\t-0.0270       = Validation score (-WQL)\n",
      "\t0.28    s     = Training runtime\n",
      "\t0.27    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. \n",
      "\t-0.0218       = Validation score (-WQL)\n",
      "\t8.17    s     = Training runtime\n",
      "\t1.81    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. \n",
      "\t-0.1476       = Validation score (-WQL)\n",
      "\t17.74   s     = Training runtime\n",
      "\t1.96    s     = Validation (prediction) runtime\n",
      "Training timeseries model ETS. \n",
      "\t-0.0207       = Validation score (-WQL)\n",
      "\t0.34    s     = Training runtime\n",
      "\t159.11  s     = Validation (prediction) runtime\n",
      "Training timeseries model Theta. \n",
      "\t-0.0203       = Validation score (-WQL)\n",
      "\t0.25    s     = Training runtime\n",
      "\t26.45   s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'Naive': 0.75, 'RecursiveTabular': 0.25}\n",
      "\t-0.0199       = Validation score (-WQL)\n",
      "\t2.51    s     = Training runtime\n",
      "\t14.03   s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'WeightedEnsemble']\n",
      "Total runtime: 234.59 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.0199\n"
     ]
    }
   ],
   "source": [
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=14,\n",
    "    target=\"target\",    #specify that target is the target and weekend a known active covariate, other dynamic features are automatically detected as known covariates\n",
    "    known_covariates_names=[\"weekend\"],\n",
    "    #eval_metric is default WQL\n",
    ").fit(train_data, presets=\"fast_training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e07287f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'domain':         Industry     Finance       Micro       Other       Macro         std  \\\n",
       " RMSE -126.281083 -582.310129 -365.533700 -104.385302 -402.593763  179.803758   \n",
       " MAE   -76.100385 -267.643768 -173.814771  -58.660795 -248.964606   85.877424   \n",
       " MAPE   -0.023005   -0.028483   -0.031536   -0.020588   -0.048381    0.009790   \n",
       " \n",
       "             cv    max_diff   mean_diff  \n",
       " RMSE -0.568602  477.924827  246.432467  \n",
       " MAE  -0.520353  208.982974  118.166034  \n",
       " MAPE -0.322068    0.027793    0.012824  }"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline = evaluate_predictions(test_data, predictor)\n",
    "df_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdf97cc",
   "metadata": {},
   "source": [
    "# Use Fairness Metric for evalauation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6918df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'c:\\Users\\Luca\\Studium\\Master\\Master-project\\AutogluonModels\\ag-20251128_105219'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          4\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.09 GB / 7.88 GB (13.9%)\n",
      "Disk Space Avail:   81.38 GB / 475.69 GB (17.1%)\n",
      "===================================================\n",
      "Setting presets to: fast_training\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MAPE_GroupFairnessScorer,\n",
      " 'hyperparameters': 'very_light',\n",
      " 'known_covariates_names': ['weekend'],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 14,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'target',\n",
      " 'verbosity': 2}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferred time series frequency: 'D'\n",
      "Provided train_data has 243060 rows, 100 time series. Median time series length is 3180 (min=101, max=4301). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'target'\n",
      "\tknown_covariates:\n",
      "\t\tcategorical:        []\n",
      "\t\tcontinuous (float): ['weekend']\n",
      "\tstatic_features:\n",
      "\t\tcategorical:        ['domain']\n",
      "\t\tcontinuous (float): []\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MAPE_GroupFairnessScorer'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-11-28 11:52:21\n",
      "Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta']\n",
      "Training timeseries model Naive. \n",
      "\t-0.0244       = Validation score (-MAPE_GroupFairnessScorer)\n",
      "\t0.65    s     = Training runtime\n",
      "\t29.73   s     = Validation (prediction) runtime\n",
      "Training timeseries model SeasonalNaive. \n",
      "\t-0.0315       = Validation score (-MAPE_GroupFairnessScorer)\n",
      "\t0.45    s     = Training runtime\n",
      "\t0.44    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. \n",
      "\t-0.0257       = Validation score (-MAPE_GroupFairnessScorer)\n",
      "\t29.49   s     = Training runtime\n",
      "\t0.74    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. \n",
      "\t-0.0342       = Validation score (-MAPE_GroupFairnessScorer)\n",
      "\t4.93    s     = Training runtime\n",
      "\t0.77    s     = Validation (prediction) runtime\n",
      "Training timeseries model ETS. \n",
      "\t-0.0242       = Validation score (-MAPE_GroupFairnessScorer)\n",
      "\t0.34    s     = Training runtime\n",
      "\t119.06  s     = Validation (prediction) runtime\n",
      "Training timeseries model Theta. \n",
      "\t-0.0249       = Validation score (-MAPE_GroupFairnessScorer)\n",
      "\t0.35    s     = Training runtime\n",
      "\t19.72   s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'ETS': 1.0}\n",
      "\t-0.0242       = Validation score (-MAPE_GroupFairnessScorer)\n",
      "\t62.94   s     = Training runtime\n",
      "\t119.06  s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'WeightedEnsemble']\n",
      "Total runtime: 271.07 s\n",
      "Best model: ETS\n",
      "Best model score: -0.0242\n"
     ]
    }
   ],
   "source": [
    "#from metrics import MAPE_GroupFairnessScorer\n",
    "\n",
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=14,\n",
    "    target=\"target\",    #specify that target is the target and weekend a known active covariate, other dynamic features are automatically detected as known covariates\n",
    "    known_covariates_names=[\"weekend\"],\n",
    "    eval_metric=MAPE_GroupFairnessScorer()# train_data.static_features\n",
    ").fit(train_data, presets=\"fast_training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02208c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model not specified in predict, will default to the model with the best validation score: ETS\n",
      "Model not specified in predict, will default to the model with the best validation score: ETS\n",
      "Model not specified in predict, will default to the model with the best validation score: ETS\n",
      "Model not specified in predict, will default to the model with the best validation score: ETS\n",
      "Model not specified in predict, will default to the model with the best validation score: ETS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>Finance</th>\n",
       "      <th>Micro</th>\n",
       "      <th>Other</th>\n",
       "      <th>Macro</th>\n",
       "      <th>std</th>\n",
       "      <th>cv</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>mean_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>-121.778391</td>\n",
       "      <td>-583.782426</td>\n",
       "      <td>-355.112093</td>\n",
       "      <td>-227.545166</td>\n",
       "      <td>-437.808754</td>\n",
       "      <td>160.845317</td>\n",
       "      <td>-0.465941</td>\n",
       "      <td>462.004035</td>\n",
       "      <td>226.854332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>-73.513268</td>\n",
       "      <td>-267.781804</td>\n",
       "      <td>-168.981017</td>\n",
       "      <td>-100.387109</td>\n",
       "      <td>-274.375031</td>\n",
       "      <td>82.905458</td>\n",
       "      <td>-0.468372</td>\n",
       "      <td>200.861763</td>\n",
       "      <td>113.823644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>-0.022205</td>\n",
       "      <td>-0.028316</td>\n",
       "      <td>-0.030521</td>\n",
       "      <td>-0.029472</td>\n",
       "      <td>-0.052896</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>-0.321613</td>\n",
       "      <td>0.030691</td>\n",
       "      <td>0.012717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Industry     Finance       Micro       Other       Macro         std  \\\n",
       "RMSE -121.778391 -583.782426 -355.112093 -227.545166 -437.808754  160.845317   \n",
       "MAE   -73.513268 -267.781804 -168.981017 -100.387109 -274.375031   82.905458   \n",
       "MAPE   -0.022205   -0.028316   -0.030521   -0.029472   -0.052896    0.010511   \n",
       "\n",
       "            cv    max_diff   mean_diff  \n",
       "RMSE -0.465941  462.004035  226.854332  \n",
       "MAE  -0.468372  200.861763  113.823644  \n",
       "MAPE -0.321613    0.030691    0.012717  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_regularization = evaluate_predictions(test_data, predictor)\n",
    "df_regularization[\"domain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe59c254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>Finance</th>\n",
       "      <th>Micro</th>\n",
       "      <th>Other</th>\n",
       "      <th>Macro</th>\n",
       "      <th>std</th>\n",
       "      <th>cv</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>mean_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>-126.281083</td>\n",
       "      <td>-582.310129</td>\n",
       "      <td>-365.533700</td>\n",
       "      <td>-104.385302</td>\n",
       "      <td>-402.593763</td>\n",
       "      <td>179.803758</td>\n",
       "      <td>-0.568602</td>\n",
       "      <td>477.924827</td>\n",
       "      <td>246.432467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>-76.100385</td>\n",
       "      <td>-267.643768</td>\n",
       "      <td>-173.814771</td>\n",
       "      <td>-58.660795</td>\n",
       "      <td>-248.964606</td>\n",
       "      <td>85.877424</td>\n",
       "      <td>-0.520353</td>\n",
       "      <td>208.982974</td>\n",
       "      <td>118.166034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>-0.023005</td>\n",
       "      <td>-0.028483</td>\n",
       "      <td>-0.031536</td>\n",
       "      <td>-0.020588</td>\n",
       "      <td>-0.048381</td>\n",
       "      <td>0.009790</td>\n",
       "      <td>-0.322068</td>\n",
       "      <td>0.027793</td>\n",
       "      <td>0.012824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>-121.778391</td>\n",
       "      <td>-583.782426</td>\n",
       "      <td>-355.112093</td>\n",
       "      <td>-227.545166</td>\n",
       "      <td>-437.808754</td>\n",
       "      <td>160.845317</td>\n",
       "      <td>-0.465941</td>\n",
       "      <td>462.004035</td>\n",
       "      <td>226.854332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>-73.513268</td>\n",
       "      <td>-267.781804</td>\n",
       "      <td>-168.981017</td>\n",
       "      <td>-100.387109</td>\n",
       "      <td>-274.375031</td>\n",
       "      <td>82.905458</td>\n",
       "      <td>-0.468372</td>\n",
       "      <td>200.861763</td>\n",
       "      <td>113.823644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>-0.022205</td>\n",
       "      <td>-0.028316</td>\n",
       "      <td>-0.030521</td>\n",
       "      <td>-0.029472</td>\n",
       "      <td>-0.052896</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>-0.321613</td>\n",
       "      <td>0.030691</td>\n",
       "      <td>0.012717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Industry     Finance       Micro       Other       Macro         std  \\\n",
       "RMSE -126.281083 -582.310129 -365.533700 -104.385302 -402.593763  179.803758   \n",
       "MAE   -76.100385 -267.643768 -173.814771  -58.660795 -248.964606   85.877424   \n",
       "MAPE   -0.023005   -0.028483   -0.031536   -0.020588   -0.048381    0.009790   \n",
       "RMSE -121.778391 -583.782426 -355.112093 -227.545166 -437.808754  160.845317   \n",
       "MAE   -73.513268 -267.781804 -168.981017 -100.387109 -274.375031   82.905458   \n",
       "MAPE   -0.022205   -0.028316   -0.030521   -0.029472   -0.052896    0.010511   \n",
       "\n",
       "            cv    max_diff   mean_diff  \n",
       "RMSE -0.568602  477.924827  246.432467  \n",
       "MAE  -0.520353  208.982974  118.166034  \n",
       "MAPE -0.322068    0.027793    0.012824  \n",
       "RMSE -0.465941  462.004035  226.854332  \n",
       "MAE  -0.468372  200.861763  113.823644  \n",
       "MAPE -0.321613    0.030691    0.012717  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_baseline[\"domain\"], df_regularization[\"domain\"]], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0978133",
   "metadata": {},
   "source": [
    "# Use sampling strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdc3fb5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "SMOTE-NC is not designed to work only with categorical features. It requires some numerical features.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 162\u001b[39m\n\u001b[32m    160\u001b[39m GROUP_COLS = [\u001b[33m\"\u001b[39m\u001b[33mdomain\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# change as needed\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[38;5;66;03m# infer categorical columns automatically; you can pass a list via categorical_cols param\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m ts_augmented_df, static_augmented_df = \u001b[43moversample_static_and_clone_series\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_features_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mitem_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGROUP_COLS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_count\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m    164\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# rebuild TimeSeriesDataFrame from the augmented datasets\u001b[39;00m\n\u001b[32m    167\u001b[39m train_data_aug = TimeSeriesDataFrame.from_data_frame(\n\u001b[32m    168\u001b[39m     ts_augmented_df,\n\u001b[32m    169\u001b[39m     id_column=\u001b[33m\"\u001b[39m\u001b[33mitem_id\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    170\u001b[39m     timestamp_column=\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    171\u001b[39m     static_features_df=static_augmented_df,\n\u001b[32m    172\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36moversample_static_and_clone_series\u001b[39m\u001b[34m(ts_df, static_df, id_col, group_cols, target_count, categorical_cols, random_state)\u001b[39m\n\u001b[32m     68\u001b[39m sampling_strategy = {g: target_count \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m to_oversample.keys()}\n\u001b[32m     70\u001b[39m smote = SMOTENC(\n\u001b[32m     71\u001b[39m     categorical_features=categorical_idx,\n\u001b[32m     72\u001b[39m     sampling_strategy=sampling_strategy,\n\u001b[32m     73\u001b[39m     random_state=random_state,\n\u001b[32m     74\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m X_res, y_res = \u001b[43msmote\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# convert to DataFrame for comparison and locating synthetic samples\u001b[39;00m\n\u001b[32m     79\u001b[39m X_df = pd.DataFrame(X.values, columns=feat_cols)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Luca\\miniconda3\\envs\\FairTS\\Lib\\site-packages\\imblearn\\base.py:202\u001b[39m, in \u001b[36mBaseSampler.fit_resample\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, **params):\n\u001b[32m    182\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[32m    183\u001b[39m \n\u001b[32m    184\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    200\u001b[39m \u001b[33;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Luca\\miniconda3\\envs\\FairTS\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Luca\\miniconda3\\envs\\FairTS\\Lib\\site-packages\\imblearn\\base.py:105\u001b[39m, in \u001b[36mSamplerMixin.fit_resample\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m     99\u001b[39m X, y, binarize_y = \u001b[38;5;28mself\u001b[39m._check_X_y(X, y)\n\u001b[32m    101\u001b[39m \u001b[38;5;28mself\u001b[39m.sampling_strategy_ = check_sampling_strategy(\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mself\u001b[39m.sampling_strategy, y, \u001b[38;5;28mself\u001b[39m._sampling_type\n\u001b[32m    103\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m y_ = (\n\u001b[32m    108\u001b[39m     label_binarize(output[\u001b[32m1\u001b[39m], classes=np.unique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[32m1\u001b[39m]\n\u001b[32m    109\u001b[39m )\n\u001b[32m    111\u001b[39m X_, y_ = arrays_transformer.transform(output[\u001b[32m0\u001b[39m], y_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Luca\\miniconda3\\envs\\FairTS\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:596\u001b[39m, in \u001b[36mSMOTENC._fit_resample\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;28mself\u001b[39m.n_features_ = _num_features(X)\n\u001b[32m    595\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_column_types(X)\n\u001b[32m--> \u001b[39m\u001b[32m596\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m X_continuous = _safe_indexing(X, \u001b[38;5;28mself\u001b[39m.continuous_features_, axis=\u001b[32m1\u001b[39m)\n\u001b[32m    599\u001b[39m X_continuous = check_array(X_continuous, accept_sparse=[\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Luca\\miniconda3\\envs\\FairTS\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:583\u001b[39m, in \u001b[36mSMOTENC._validate_estimator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;28msuper\u001b[39m()._validate_estimator()\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.categorical_features_.size == \u001b[38;5;28mself\u001b[39m.n_features_in_:\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    584\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSMOTE-NC is not designed to work only with categorical \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfeatures. It requires some numerical features.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    586\u001b[39m     )\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.categorical_features_.size == \u001b[32m0\u001b[39m:\n\u001b[32m    588\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    589\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSMOTE-NC is not designed to work only with numerical \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    590\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfeatures. It requires some categorical features.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    591\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: SMOTE-NC is not designed to work only with categorical features. It requires some numerical features."
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "# Insert after the \"Use sampling strategy\" markdown cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "def oversample_static_and_clone_series(\n",
    "    ts_df,\n",
    "    static_df,\n",
    "    id_col=\"item_id\",\n",
    "    group_cols=None,\n",
    "    target_count=None,\n",
    "    categorical_cols=None,\n",
    "    random_state=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Oversample under-represented groups defined by group_cols using SMOTENC on the static features.\n",
    "    For each synthetic static sample, clone an existing time series from the same group (nearest/or random)\n",
    "    and assign a new unique id. Returns augmented (ts_df_aug, static_df_aug).\n",
    "\n",
    "    - ts_df: original time series dataframe (long format with id_col and timestamp and target)\n",
    "    - static_df: dataframe keyed by id_col with static features\n",
    "    - group_cols: list of columns in static_df that define the \"group\" to balance (e.g. ['Age', 'Gender'])\n",
    "    - target_count: desired count per group (if None uses max existing group count)\n",
    "    - categorical_cols: list of categorical columns in static_df (None => infer object dtype)\n",
    "    \"\"\"\n",
    "    if group_cols is None:\n",
    "        raise ValueError(\"group_cols must be provided\")\n",
    "\n",
    "    static = static_df.copy().reset_index(drop=True)\n",
    "    static[id_col] = static[id_col].astype(str)\n",
    "\n",
    "    # compute group key\n",
    "    static[\"_group_key\"] = static[group_cols].astype(str).agg(\"__\".join, axis=1)\n",
    "    counts = static[\"_group_key\"].value_counts().to_dict()\n",
    "    max_count = max(counts.values())\n",
    "    if target_count is None:\n",
    "        target_count = max_count\n",
    "\n",
    "    # decide which groups to oversample\n",
    "    to_oversample = {g: target_count - c for g, c in counts.items() if c < target_count}\n",
    "    if not to_oversample:\n",
    "        print(\"No groups need oversampling (already balanced).\")\n",
    "        return ts_df, static_df\n",
    "\n",
    "    # Prepare features for SMOTENC: use all static columns except the id and temporary group key\n",
    "    feat_cols = [c for c in static.columns if c not in [id_col, \"_group_key\"]]\n",
    "    # infer categorical cols if not given\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = [c for c in feat_cols if static[c].dtype == \"object\" or str(static[c].dtype).startswith(\"category\")]\n",
    "    categorical_idx = [feat_cols.index(c) for c in categorical_cols if c in feat_cols]\n",
    "\n",
    "    # encode categorical cols as ordinal integers (SMOTENC requires integer categories)\n",
    "    enc = OrdinalEncoder(dtype=int)\n",
    "    X = static[feat_cols].copy()\n",
    "    if categorical_cols:\n",
    "        X[categorical_cols] = enc.fit_transform(X[categorical_cols].astype(str))\n",
    "    else:\n",
    "        # ensure numeric array\n",
    "        X = X.astype(float)\n",
    "\n",
    "    y = static[\"_group_key\"].values\n",
    "\n",
    "    # build sampling_strategy dict for classes needing samples\n",
    "    sampling_strategy = {g: target_count for g in to_oversample.keys()}\n",
    "\n",
    "    smote = SMOTENC(\n",
    "        categorical_features=categorical_idx,\n",
    "        sampling_strategy=sampling_strategy,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    X_res, y_res = smote.fit_resample(X.values, y)\n",
    "\n",
    "    # convert to DataFrame for comparison and locating synthetic samples\n",
    "    X_df = pd.DataFrame(X.values, columns=feat_cols)\n",
    "    X_res_df = pd.DataFrame(X_res, columns=feat_cols)\n",
    "    y_res_ser = pd.Series(y_res, name=\"_group_key\")\n",
    "\n",
    "    # find synthetic rows (those in resampled but not in original)\n",
    "    # comparing tuples of all features (categorical are integers matching original encoding)\n",
    "    orig_tuples = set([tuple(row) for row in X_df.itertuples(index=False, name=None)])\n",
    "    res_tuples = [tuple(row) for row in X_res_df.itertuples(index=False, name=None)]\n",
    "\n",
    "    synthetic_indices = [i for i, t in enumerate(res_tuples) if t not in orig_tuples]\n",
    "    if not synthetic_indices:\n",
    "        print(\"SMOTENC did not create synthetic samples (unexpected).\")\n",
    "        return ts_df, static_df\n",
    "\n",
    "    new_static_rows = []\n",
    "    new_series_rows = []\n",
    "    # map group key -> list of original ids (to sample donors)\n",
    "    group_to_ids = static.groupby(\"_group_key\")[id_col].apply(list).to_dict()\n",
    "\n",
    "    for idx in synthetic_indices:\n",
    "        row_enc = X_res_df.iloc[idx]\n",
    "        group_key = y_res_ser.iloc[idx]\n",
    "\n",
    "        # decode categorical columns back to original labels if necessary\n",
    "        row_decoded = row_enc.copy()\n",
    "        if categorical_cols:\n",
    "            # inverse transform categorical subset\n",
    "            cat_vals = row_enc[categorical_cols].values.reshape(1, -1)\n",
    "            cat_decoded = enc.inverse_transform(cat_vals)\n",
    "            for j, c in enumerate(categorical_cols):\n",
    "                row_decoded[c] = cat_decoded[0, j]\n",
    "\n",
    "        # build a new id and static row\n",
    "        new_id = str(uuid.uuid4())\n",
    "        new_row = {id_col: new_id}\n",
    "        for c in feat_cols:\n",
    "            new_row[c] = row_decoded[c]\n",
    "        # reconstruct group cols from group_key when possible, otherwise copy from decoded fields\n",
    "        # (group_key is combination of group_cols separated by \"__\")\n",
    "        parts = group_key.split(\"__\")\n",
    "        for i, gc in enumerate(group_cols):\n",
    "            if i < len(parts):\n",
    "                # attempt to cast back to original dtype\n",
    "                new_row[gc] = parts[i]\n",
    "        new_static_rows.append(new_row)\n",
    "\n",
    "        # choose a donor time series from same group (random)\n",
    "        donors = group_to_ids.get(group_key)\n",
    "        if not donors:\n",
    "            # if only synthetic groups (rare) fallback to random original id\n",
    "            donor_id = static[id_col].iloc[np.random.randint(len(static))]\n",
    "        else:\n",
    "            donor_id = np.random.choice(donors)\n",
    "        # copy all rows in ts_df with donor_id and assign new_id\n",
    "        donor_rows = ts_df[ts_df[id_col].astype(str) == str(donor_id)].copy()\n",
    "        if donor_rows.empty:\n",
    "            # fallback: skip if donor has no series\n",
    "            continue\n",
    "        donor_rows[id_col] = new_id\n",
    "        # optional: jitter the target slightly to avoid exact duplicates (small gaussian noise)\n",
    "        if \"target\" in donor_rows.columns:\n",
    "            donor_rows[\"target\"] = donor_rows[\"target\"].astype(float) * (1.0 + np.random.normal(0, 0.01, size=len(donor_rows)))\n",
    "        new_series_rows.append(donor_rows)\n",
    "\n",
    "    if not new_static_rows:\n",
    "        print(\"No new static rows created.\")\n",
    "        return ts_df, static_df\n",
    "\n",
    "    # append new static rows\n",
    "    static_aug = pd.concat([static_df.reset_index(drop=True), pd.DataFrame(new_static_rows)], ignore_index=True)\n",
    "    # append new series rows\n",
    "    ts_aug = pd.concat([ts_df, pd.concat(new_series_rows, ignore_index=True)], ignore_index=True)\n",
    "\n",
    "    # ensure id types match original\n",
    "    ts_aug[id_col] = ts_aug[id_col].astype(str)\n",
    "    static_aug[id_col] = static_aug[id_col].astype(str)\n",
    "\n",
    "    return ts_aug, static_aug.drop(columns=[\"_group_key\"], errors=\"ignore\")\n",
    "\n",
    "# Example usage in this notebook\n",
    "# choose group columns to balance (adjust to your dataset)\n",
    "GROUP_COLS = [\"domain\"]  # change as needed\n",
    "# infer categorical columns automatically; you can pass a list via categorical_cols param\n",
    "ts_augmented_df, static_augmented_df = oversample_static_and_clone_series(\n",
    "    df, static_features_df, id_col=\"item_id\", group_cols=GROUP_COLS, target_count=None, random_state=42\n",
    ")\n",
    "\n",
    "# rebuild TimeSeriesDataFrame from the augmented datasets\n",
    "train_data_aug = TimeSeriesDataFrame.from_data_frame(\n",
    "    ts_augmented_df,\n",
    "    id_column=\"item_id\",\n",
    "    timestamp_column=\"timestamp\",\n",
    "    static_features_df=static_augmented_df,\n",
    ")\n",
    "\n",
    "print(\"Original series count:\", static_features_df.shape[0])\n",
    "print(\"Augmented series count:\", static_augmented_df.shape[0])\n",
    "\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c513681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FairTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
