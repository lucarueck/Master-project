{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e63ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luca\\miniconda3\\envs\\LongTerm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc8c2a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"possible_datasets/inequality_education_fev.parquet\")\n",
    "X = df.drop(columns=[\"target\", \"id\", \"timestamp\"])\n",
    "y = df[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=df[\"Human Development Groups\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f973ef4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\AppData\\Local\\Temp\\ipykernel_14104\\1248752832.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\b\\abs_bao0hdcrdh\\croot\\pytorch_1675190257512\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  X = torch.tensor( [np.hstack(X_train.values[i]) for i in range(len(X_train))], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Gesamtverlust=757.3701 (MSE=751.9115, Fairness=10.9171)\n",
      "Epoch 1000: Gesamtverlust=1.2333 (MSE=1.0914, Fairness=0.2839)\n",
      "Epoch 2000: Gesamtverlust=0.2652 (MSE=0.1945, Fairness=0.1413)\n",
      "Epoch 3000: Gesamtverlust=0.0571 (MSE=0.0270, Fairness=0.0602)\n",
      "Epoch 4000: Gesamtverlust=0.0328 (MSE=0.0128, Fairness=0.0399)\n",
      "Epoch 5000: Gesamtverlust=0.0157 (MSE=0.0045, Fairness=0.0224)\n",
      "Epoch 6000: Gesamtverlust=0.0082 (MSE=0.0031, Fairness=0.0102)\n",
      "Epoch 7000: Gesamtverlust=0.0039 (MSE=0.0006, Fairness=0.0066)\n",
      "Epoch 8000: Gesamtverlust=0.0022 (MSE=0.0003, Fairness=0.0038)\n",
      "Epoch 9000: Gesamtverlust=0.0015 (MSE=0.0002, Fairness=0.0026)\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0: Gesamtverlust=738.6561 (MSE=738.6561, Fairness=10.7734)\n",
      "Epoch 1000: Gesamtverlust=1.0125 (MSE=1.0125, Fairness=0.2789)\n",
      "Epoch 2000: Gesamtverlust=0.1663 (MSE=0.1663, Fairness=0.1230)\n",
      "Epoch 3000: Gesamtverlust=0.0145 (MSE=0.0145, Fairness=0.0159)\n",
      "Epoch 4000: Gesamtverlust=0.0050 (MSE=0.0050, Fairness=0.0105)\n",
      "Epoch 5000: Gesamtverlust=0.0019 (MSE=0.0019, Fairness=0.0085)\n",
      "Epoch 6000: Gesamtverlust=0.0008 (MSE=0.0008, Fairness=0.0075)\n",
      "Epoch 7000: Gesamtverlust=0.0004 (MSE=0.0004, Fairness=0.0057)\n",
      "Epoch 8000: Gesamtverlust=0.0002 (MSE=0.0002, Fairness=0.0039)\n",
      "Epoch 9000: Gesamtverlust=0.0001 (MSE=0.0001, Fairness=0.0027)\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor( [np.hstack(X_train.values[i]) for i in range(len(X_train))], dtype=torch.float32)\n",
    "y = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "groups = torch.tensor(X_train[\"Human Development Groups\"], dtype=torch.int64) #fairness groups\n",
    "\n",
    "\n",
    "# Simple model\n",
    "class GlobalTimeSeriesModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Fairness penalty\n",
    "def fairness_penalty(y_true, y_pred, groups):\n",
    "    \"\"\"Differenz der mittleren Fehler zwischen Gruppen.\"\"\"\n",
    "    errors = torch.abs(y_true - y_pred).detach()\n",
    "    groups_err = []\n",
    "    groups_err.append(errors[groups == 0].mean()) \n",
    "    groups_err.append(errors[groups == 1].mean())\n",
    "    groups_err.append(errors[groups == 2].mean())\n",
    "    groups_err.append(errors[groups == 3].mean())\n",
    "    return np.std(np.array(groups_err))\n",
    "\n",
    "\n",
    "def train(model, with_fairness=True):\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "  criterion = nn.MSELoss()\n",
    "  lambda_fair = 0.5  # Gewichtung der Fairness-Strafe\n",
    "\n",
    "  for epoch in range(10000):\n",
    "      optimizer.zero_grad()\n",
    "      y_pred = model(X)\n",
    "      mse_loss = criterion(y_pred, y)\n",
    "      fair_loss = fairness_penalty(y, y_pred, groups)\n",
    "      if with_fairness:\n",
    "        loss = mse_loss + lambda_fair * fair_loss\n",
    "      else:\n",
    "        loss = mse_loss\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      if epoch % 1000 == 0:\n",
    "          print(f\"Epoch {epoch}: Gesamtverlust={loss.item():.4f} \"\n",
    "                f\"(MSE={mse_loss.item():.4f}, Fairness={fair_loss.item():.4f})\")\n",
    "\n",
    "model1 = GlobalTimeSeriesModel(input_size=len(X[0]), hidden_size=9)\n",
    "model2 = GlobalTimeSeriesModel(input_size=len(X[0]), hidden_size=9)\n",
    "\n",
    "train(model1, with_fairness=True)\n",
    "print(\"\\n\\n\")\n",
    "train(model2, with_fairness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "842bc950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.1171\n",
      "Test fairness (std of group mean abs errors): 0.1355\n",
      "\n",
      "\n",
      "\n",
      "Test MSE: 0.0814\n",
      "Test fairness (std of group mean abs errors): 0.0913\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.tensor([np.hstack(X_test.values[i]) for i in range(len(X_test))], dtype=torch.float32)\n",
    "\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "def test(model):\n",
    "    preds = model(X_test_tensor)  \n",
    "    test_mse = nn.MSELoss()(preds, y_test_tensor).item()\n",
    "\n",
    "    groups_test = torch.tensor(X_test[\"Human Development Groups\"].values, dtype=torch.int64)\n",
    "    test_fairness = fairness_penalty(y_test_tensor, preds, groups_test).item()\n",
    "\n",
    "\n",
    "    print(f\"Test MSE: {test_mse:.4f}\")\n",
    "    print(f\"Test fairness (std of group mean abs errors): {test_fairness:.4f}\")\n",
    "\n",
    "test(model1)\n",
    "print(\"\\n\\n\")\n",
    "test(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f5cc64",
   "metadata": {},
   "source": [
    "# Walmart Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76afc6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luca\\miniconda3\\envs\\LongTerm\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Luca\\.cache\\huggingface\\hub\\datasets--autogluon--fev_datasets. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Generating train split: 100%|██████████| 30490/30490 [00:09<00:00, 3253.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Lade den Datensatz\n",
    "ds = load_dataset(\"autogluon/fev_datasets\", \"m5_1D\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d2d3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LongTerm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
