{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cffbc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6bd8204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Hospital_Name</th>\n",
       "      <th>Admission_Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-17</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Saudi</td>\n",
       "      <td>King Abdulaziz Medical City</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-17</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Saudi</td>\n",
       "      <td>King Abdulaziz Medical City</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-17</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Saudi</td>\n",
       "      <td>King Abdulaziz Medical City</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-17</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Saudi</td>\n",
       "      <td>King Abdulaziz Medical City</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-17</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Saudi</td>\n",
       "      <td>King Abdulaziz Medical City</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>65+</td>\n",
       "      <td>Male</td>\n",
       "      <td>Saudi</td>\n",
       "      <td>King Saud Medical City</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>65+</td>\n",
       "      <td>Male</td>\n",
       "      <td>Saudi</td>\n",
       "      <td>King Saud Medical City</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>65+</td>\n",
       "      <td>Male</td>\n",
       "      <td>Saudi</td>\n",
       "      <td>King Saud Medical City</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>65+</td>\n",
       "      <td>Male</td>\n",
       "      <td>Saudi</td>\n",
       "      <td>King Saud Medical City</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>65+</td>\n",
       "      <td>Male</td>\n",
       "      <td>Saudi</td>\n",
       "      <td>King Saud Medical City</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Gender Nationality                Hospital_Name  Admission_Counts\n",
       "0     0-17  Female   Non-Saudi  King Abdulaziz Medical City                 6\n",
       "1     0-17  Female   Non-Saudi  King Abdulaziz Medical City                 7\n",
       "2     0-17  Female   Non-Saudi  King Abdulaziz Medical City                 2\n",
       "3     0-17  Female   Non-Saudi  King Abdulaziz Medical City                 5\n",
       "4     0-17  Female   Non-Saudi  King Abdulaziz Medical City                 3\n",
       "...    ...     ...         ...                          ...               ...\n",
       "4795   65+    Male       Saudi       King Saud Medical City                23\n",
       "4796   65+    Male       Saudi       King Saud Medical City                31\n",
       "4797   65+    Male       Saudi       King Saud Medical City                31\n",
       "4798   65+    Male       Saudi       King Saud Medical City                24\n",
       "4799   65+    Male       Saudi       King Saud Medical City                24\n",
       "\n",
       "[4800 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ryiadh = pd.read_csv(\"../possible_datasets/KSMC_Hospital/data_preprocessed.csv\")\n",
    "df_ryiadh.drop(columns=[\"Admission_Date\"], inplace=True)        #dates are for every time series the same so using them in modeling does not make sense\n",
    "df_ryiadh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ed86969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ryiadh = df_ryiadh.pivot_table(index=[\"Age\", \"Gender\", \"Nationality\", \"Hospital_Name\"], aggfunc=list).reset_index()\n",
    "df_ryiadh[\"target\"] = [a[63:] for a in df_ryiadh[\"Admission_Counts\"]]\n",
    "df_ryiadh[\"Admission_Counts\"] = [a[:63] for a in df_ryiadh[\"Admission_Counts\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8beedd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% train, 20% temp\n",
    "x_dyn_train, x_dyn_temp, y_train, y_temp, x_static_train, x_static_temp = train_test_split(\n",
    "    df_ryiadh[[\"Admission_Counts\"]], df_ryiadh[\"target\"], df_ryiadh[[\"Age\", \"Gender\", \"Nationality\", \"Hospital_Name\"]], test_size=0.20, random_state=42, \n",
    ")\n",
    "\n",
    "# 50/50 split of the 20% -> 10% val, 10% test\n",
    "x_dyn_val, x_dyn_test, y_val, y_test, x_static_val, x_static_test = train_test_split(\n",
    "    x_dyn_temp, y_temp, x_static_temp, test_size=0.50, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0813cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False, dtype=np.float32, drop='first')\n",
    "ohe = ohe.fit(df_ryiadh[[\"Hospital_Name\"]])\n",
    "\n",
    "# encode categorical variables (Label Encoding and One-Hot Encoding)\n",
    "def preprocess_static(df):\n",
    "    df[\"Age\"] = df[\"Age\"].apply(lambda x: 0. if x == '0-17' else 1. if x == '18-45' else 2. if x == '46-65' else 3)\n",
    "    df[\"Gender\"] = df[\"Gender\"].apply(lambda x: 0. if x == 'Female' else 1.)\n",
    "    df[\"Nationality\"] = df[\"Nationality\"].apply(lambda x: 0. if x == 'Non-Saudi' else 1.)\n",
    "    \n",
    "    df_ohe = pd.DataFrame(\n",
    "        ohe.fit_transform(df[[\"Hospital_Name\"]]), columns=ohe.get_feature_names_out([\"Hospital_Name\"])\n",
    "    )\n",
    "    df = pd.concat([df.reset_index(drop=True), df_ohe.reset_index(drop=True)], axis=1).reset_index(drop=True)\n",
    "    df = df.drop(columns=[\"Hospital_Name\"])\n",
    "    return torch.tensor(df.values).float()\n",
    "#todo admission month circular encoding\n",
    "\n",
    "x_static_train = preprocess_static(x_static_train)\n",
    "x_static_val = preprocess_static(x_static_val)\n",
    "x_static_test = preprocess_static(x_static_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfdd7eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize over all time steps and time series, todo ask if this is right\n",
    "scaler = StandardScaler()\n",
    "all_counts = np.concatenate(df_ryiadh[\"Admission_Counts\"].values)  \n",
    "all_counts = np.asarray(all_counts, dtype=float)\n",
    "\n",
    "overall_max = all_counts.max()\n",
    "overall_std = all_counts.std(ddof=0)  # ddof=1 für Stichproben-Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6baaa42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_counts(df):\n",
    "    standardize_counts = [(a - overall_max) / overall_std for a in df[\"Admission_Counts\"]]\n",
    "    return torch.tensor(standardize_counts).float().unsqueeze(-1)\n",
    "\n",
    "x_dyn_train = standardize_counts(x_dyn_train)\n",
    "x_dyn_val = standardize_counts(x_dyn_val)\n",
    "x_dyn_test = standardize_counts(x_dyn_test)\n",
    "\n",
    "def convert_y_to_tensor(df):\n",
    "    return torch.tensor(np.array(df.values.tolist(), dtype=np.float32)).float().unsqueeze(-1)\n",
    "\n",
    "y_train = convert_y_to_tensor(y_train)\n",
    "y_val = convert_y_to_tensor(y_val)\n",
    "y_test = convert_y_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c65498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, dilation=1):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) * dilation\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                               padding=padding, dilation=dilation)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
    "                               padding=padding, dilation=dilation)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, kernel_size=1) \\\n",
    "            if in_channels != out_channels else None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu1(self.conv1(x))\n",
    "        out = self.relu2(self.conv2(out))\n",
    "        \n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        # Output kürzen wegen Padding\n",
    "        out = out[..., :res.shape[-1]]\n",
    "        return out + res\n",
    "\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_features=3, output_steps=12, hidden=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tblock1 = TemporalBlock(input_features, hidden, dilation=1)\n",
    "        self.tblock2 = TemporalBlock(hidden, hidden, dilation=2)\n",
    "        self.tblock3 = TemporalBlock(hidden, hidden, dilation=4)\n",
    "\n",
    "        # letzer linearer Kopf für Forecast-Horizon\n",
    "        self.head = nn.Conv1d(hidden, output_steps, kernel_size=1)\n",
    "\n",
    "    def forward(self, x_dyn, x_static=None):\n",
    "        \"\"\"\n",
    "        x_dyn:    [batch, seq_len, features]\n",
    "        x_static: [batch, n_static] (wird NICHT in Modell verwendet)\n",
    "        \"\"\"\n",
    "        x = x_dyn.transpose(1, 2)  # → [batch, features, seq_len]\n",
    "        \n",
    "        x = self.tblock1(x)\n",
    "        x = self.tblock2(x)\n",
    "        x = self.tblock3(x)\n",
    "\n",
    "        out = self.head(x)  # [batch, output_steps, seq_len]\n",
    "\n",
    "        # Letzten Zeitschritt extrahieren (klassisch bei TCN Forecasting)\n",
    "        out = out[:, :, -1]  # [batch, output_steps]\n",
    "\n",
    "        return out.unsqueeze(-1)  # → [batch, output_steps, 1]\n",
    "    \n",
    "\n",
    "\n",
    "class GroupFairnessMAEVariance(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, preds, target, static_features):\n",
    "        # preds, target: [batch, seq_len, 1]\n",
    "        # static_features: [batch, n_static]\n",
    "        mae = torch.abs(preds - target).mean(dim=1)  # mitteln über seq_len -> [batch, 1]\n",
    "        group_vars = []\n",
    "        for i in range(static_features.shape[1]):\n",
    "            group_vals = static_features[:, i]  # [batch]\n",
    "            unique_groups = torch.unique(group_vals)\n",
    "            if len(unique_groups) <= 1:\n",
    "                continue  # überspringen, wenn nur eine Gruppe vorhanden ist\n",
    "            group_maes = []\n",
    "            for g in unique_groups:\n",
    "                mask = (group_vals == g)\n",
    "                if mask.sum() > 0:\n",
    "                    group_maes.append(mae[mask].mean())\n",
    "            group_maes = torch.stack(group_maes)\n",
    "            group_vars.append(group_maes.var())  # Varianz der Gruppen-MAEs\n",
    "        return torch.stack(group_vars).mean()  # mitteln über alle statischen Merkmale\n",
    "\n",
    "class MAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, preds, target, static_features):\n",
    "        return torch.abs(preds - target).mean()\n",
    "    \n",
    "class MAE_GroupFairness(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.mae = MAE()\n",
    "        self.fairness = GroupFairnessMAEVariance()\n",
    "    \n",
    "    def forward(self, preds, target, static_features):\n",
    "        return self.alpha * self.mae(preds, target, static_features) + (1 - self.alpha) * self.fairness(preds, target, static_features)\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    x_dyn_train, y_train, x_static_train,\n",
    "    x_dyn_val, y_val, x_static_val, loss_fn, log_metrics={},\n",
    "    epochs=50, lr=1e-3, batch_size=16,\n",
    "    patience=5, print_every=1\n",
    "):\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    model = TCN(input_features=x_dyn_train.shape[-1], output_steps=y_train.shape[1])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    n_train = x_dyn_train.shape[0]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle training data\n",
    "        permutation = torch.randperm(n_train)\n",
    "        for i in range(0, n_train, batch_size):\n",
    "            idx = permutation[i:i+batch_size]\n",
    "            bx, by, bs = x_dyn_train[idx], y_train[idx], x_static_train[idx]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            preds = model(bx, bs)\n",
    "            loss = loss_fn(preds, by, bs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        with torch.no_grad():\n",
    "            val_preds = model(x_dyn_val, x_static_val)\n",
    "            val_loss = loss_fn(val_preds, y_val, x_static_val).item()\n",
    "        \n",
    "        # Logging\n",
    "        if (epoch+1) % print_every == 0:\n",
    "            msg = f\"Epoch {epoch+1}/{epochs} | Val Loss: {val_loss:.4f}\"\n",
    "            for name, metric_fn in log_metrics.items():\n",
    "                val = metric_fn(val_preds, y_val, x_static_val)\n",
    "                msg += f\" | {name}: {val.item():.4f}\"\n",
    "            print(msg)\n",
    "        \n",
    "        # --- Early Stopping Check ---\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()  # besten Zustand speichern\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d9e278f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Val Loss: 26.7783 | Fairness_MAE_Var: 38.7627 | MAE: 14.7939\n",
      "Epoch 2/50 | Val Loss: 26.5834 | Fairness_MAE_Var: 38.1320 | MAE: 15.0348\n",
      "Epoch 3/50 | Val Loss: 26.3858 | Fairness_MAE_Var: 37.4228 | MAE: 15.3489\n",
      "Epoch 4/50 | Val Loss: 26.1074 | Fairness_MAE_Var: 36.5290 | MAE: 15.6858\n",
      "Epoch 5/50 | Val Loss: 25.6954 | Fairness_MAE_Var: 35.2814 | MAE: 16.1094\n",
      "Epoch 6/50 | Val Loss: 25.2008 | Fairness_MAE_Var: 33.8064 | MAE: 16.5953\n",
      "Epoch 7/50 | Val Loss: 24.4788 | Fairness_MAE_Var: 31.7968 | MAE: 17.1609\n",
      "Epoch 8/50 | Val Loss: 23.4384 | Fairness_MAE_Var: 29.0050 | MAE: 17.8718\n",
      "Epoch 9/50 | Val Loss: 21.9975 | Fairness_MAE_Var: 25.1011 | MAE: 18.8940\n",
      "Epoch 10/50 | Val Loss: 19.7815 | Fairness_MAE_Var: 19.1072 | MAE: 20.4558\n",
      "Epoch 11/50 | Val Loss: 16.9937 | Fairness_MAE_Var: 10.7505 | MAE: 23.2370\n",
      "Epoch 12/50 | Val Loss: 14.3709 | Fairness_MAE_Var: 3.0891 | MAE: 25.6526\n",
      "Epoch 13/50 | Val Loss: 12.7990 | Fairness_MAE_Var: 0.1195 | MAE: 25.4785\n",
      "Epoch 14/50 | Val Loss: 9.1783 | Fairness_MAE_Var: 7.1437 | MAE: 11.2128\n",
      "Epoch 15/50 | Val Loss: 8.9323 | Fairness_MAE_Var: 6.0528 | MAE: 11.8117\n",
      "Epoch 16/50 | Val Loss: 10.6365 | Fairness_MAE_Var: 8.4931 | MAE: 12.7799\n",
      "Epoch 17/50 | Val Loss: 5.1602 | Fairness_MAE_Var: 1.0643 | MAE: 9.2561\n",
      "Epoch 18/50 | Val Loss: 13.5259 | Fairness_MAE_Var: 8.9733 | MAE: 18.0784\n",
      "Epoch 19/50 | Val Loss: 8.6982 | Fairness_MAE_Var: 2.5178 | MAE: 14.8786\n",
      "Epoch 20/50 | Val Loss: 6.4388 | Fairness_MAE_Var: 0.7277 | MAE: 12.1498\n",
      "Epoch 21/50 | Val Loss: 9.9755 | Fairness_MAE_Var: 5.6973 | MAE: 14.2537\n",
      "Epoch 22/50 | Val Loss: 5.1174 | Fairness_MAE_Var: 0.2085 | MAE: 10.0264\n",
      "Epoch 23/50 | Val Loss: 6.2095 | Fairness_MAE_Var: 1.5453 | MAE: 10.8738\n",
      "Epoch 24/50 | Val Loss: 5.9491 | Fairness_MAE_Var: 1.3050 | MAE: 10.5932\n",
      "Epoch 25/50 | Val Loss: 4.7978 | Fairness_MAE_Var: 0.2987 | MAE: 9.2969\n",
      "Epoch 26/50 | Val Loss: 4.3138 | Fairness_MAE_Var: 0.1222 | MAE: 8.5055\n",
      "Epoch 27/50 | Val Loss: 4.1056 | Fairness_MAE_Var: 0.1190 | MAE: 8.0922\n",
      "Epoch 28/50 | Val Loss: 3.9289 | Fairness_MAE_Var: 0.1089 | MAE: 7.7489\n",
      "Epoch 29/50 | Val Loss: 4.0848 | Fairness_MAE_Var: 0.3838 | MAE: 7.7858\n",
      "Epoch 30/50 | Val Loss: 3.3718 | Fairness_MAE_Var: 0.1050 | MAE: 6.6387\n",
      "Epoch 31/50 | Val Loss: 3.0714 | Fairness_MAE_Var: 0.0868 | MAE: 6.0560\n",
      "Epoch 32/50 | Val Loss: 2.8049 | Fairness_MAE_Var: 0.1610 | MAE: 5.4487\n",
      "Epoch 33/50 | Val Loss: 3.3954 | Fairness_MAE_Var: 0.4938 | MAE: 6.2970\n",
      "Epoch 34/50 | Val Loss: 2.2963 | Fairness_MAE_Var: 0.0792 | MAE: 4.5134\n",
      "Epoch 35/50 | Val Loss: 2.2552 | Fairness_MAE_Var: 0.1302 | MAE: 4.3802\n",
      "Epoch 36/50 | Val Loss: 2.4207 | Fairness_MAE_Var: 0.1429 | MAE: 4.6985\n",
      "Epoch 37/50 | Val Loss: 2.1454 | Fairness_MAE_Var: 0.1724 | MAE: 4.1184\n",
      "Epoch 38/50 | Val Loss: 2.7150 | Fairness_MAE_Var: 0.0576 | MAE: 5.3724\n",
      "Epoch 39/50 | Val Loss: 2.2302 | Fairness_MAE_Var: 0.3100 | MAE: 4.1505\n",
      "Epoch 40/50 | Val Loss: 2.5051 | Fairness_MAE_Var: 0.2910 | MAE: 4.7191\n",
      "Epoch 41/50 | Val Loss: 2.5271 | Fairness_MAE_Var: 0.6997 | MAE: 4.3545\n",
      "Epoch 42/50 | Val Loss: 2.2473 | Fairness_MAE_Var: 0.4703 | MAE: 4.0244\n",
      "Early stopping at epoch 42\n"
     ]
    }
   ],
   "source": [
    "model = train_model(x_dyn_train, y_train, x_static_train, x_dyn_val, y_val, x_static_val, loss_fn=MAE_GroupFairness(),\n",
    "                    log_metrics={\"Fairness_MAE_Var\": GroupFairnessMAEVariance(), \"MAE\": MAE()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8f99a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 3.4493825435638428\n",
      "Test Fairness: 0.24558070302009583\n",
      "Test Combined: 1.847481608390808\n"
     ]
    }
   ],
   "source": [
    "group_fairness_metric = GroupFairnessMAEVariance()\n",
    "mae_metric = MAE()\n",
    "mae_group_fairness_metric = MAE_GroupFairness()\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds_test = model(x_dyn_test, x_static_test)\n",
    "    test_mae = mae_metric(preds_test, y_test, x_static_test).item()\n",
    "    test_fairness = group_fairness_metric(preds_test, y_test, x_static_test).item()\n",
    "    test_combined = mae_group_fairness_metric(preds_test, y_test, x_static_test).item()\n",
    "\n",
    "print(\"Test MAE:\", test_mae)\n",
    "print(\"Test Fairness:\", test_fairness)\n",
    "print(\"Test Combined:\", test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f34a0d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Val Loss: 13.7788 | Fairness_MAE_Var: 40.7681 | MAE: 13.7788\n",
      "Epoch 2/50 | Val Loss: 12.9184 | Fairness_MAE_Var: 41.7945 | MAE: 12.9184\n",
      "Epoch 3/50 | Val Loss: 11.6873 | Fairness_MAE_Var: 43.0028 | MAE: 11.6873\n",
      "Epoch 4/50 | Val Loss: 10.5048 | Fairness_MAE_Var: 37.7481 | MAE: 10.5048\n",
      "Epoch 5/50 | Val Loss: 9.7977 | Fairness_MAE_Var: 25.1472 | MAE: 9.7977\n",
      "Epoch 6/50 | Val Loss: 9.4295 | Fairness_MAE_Var: 16.7060 | MAE: 9.4295\n",
      "Epoch 7/50 | Val Loss: 9.2546 | Fairness_MAE_Var: 12.2287 | MAE: 9.2546\n",
      "Epoch 8/50 | Val Loss: 9.1791 | Fairness_MAE_Var: 10.8502 | MAE: 9.1791\n",
      "Epoch 9/50 | Val Loss: 9.0674 | Fairness_MAE_Var: 13.9285 | MAE: 9.0674\n",
      "Epoch 10/50 | Val Loss: 8.9734 | Fairness_MAE_Var: 17.3466 | MAE: 8.9734\n",
      "Epoch 11/50 | Val Loss: 8.8904 | Fairness_MAE_Var: 25.3736 | MAE: 8.8904\n",
      "Epoch 12/50 | Val Loss: 8.9168 | Fairness_MAE_Var: 29.7285 | MAE: 8.9168\n",
      "Epoch 13/50 | Val Loss: 8.8834 | Fairness_MAE_Var: 30.1334 | MAE: 8.8834\n",
      "Epoch 14/50 | Val Loss: 8.9543 | Fairness_MAE_Var: 33.9693 | MAE: 8.9543\n",
      "Epoch 15/50 | Val Loss: 8.8427 | Fairness_MAE_Var: 32.4168 | MAE: 8.8427\n",
      "Epoch 16/50 | Val Loss: 8.7747 | Fairness_MAE_Var: 30.9265 | MAE: 8.7747\n",
      "Epoch 17/50 | Val Loss: 8.7388 | Fairness_MAE_Var: 30.8315 | MAE: 8.7388\n",
      "Epoch 18/50 | Val Loss: 8.7659 | Fairness_MAE_Var: 33.3591 | MAE: 8.7659\n",
      "Epoch 19/50 | Val Loss: 8.7142 | Fairness_MAE_Var: 33.0196 | MAE: 8.7142\n",
      "Epoch 20/50 | Val Loss: 8.5393 | Fairness_MAE_Var: 27.9771 | MAE: 8.5393\n",
      "Epoch 21/50 | Val Loss: 8.4783 | Fairness_MAE_Var: 21.9618 | MAE: 8.4783\n",
      "Epoch 22/50 | Val Loss: 8.4197 | Fairness_MAE_Var: 16.1220 | MAE: 8.4197\n",
      "Epoch 23/50 | Val Loss: 8.3453 | Fairness_MAE_Var: 15.3674 | MAE: 8.3453\n",
      "Epoch 24/50 | Val Loss: 8.2664 | Fairness_MAE_Var: 21.1090 | MAE: 8.2664\n",
      "Epoch 25/50 | Val Loss: 8.1876 | Fairness_MAE_Var: 23.4901 | MAE: 8.1876\n",
      "Epoch 26/50 | Val Loss: 8.0723 | Fairness_MAE_Var: 22.7451 | MAE: 8.0723\n",
      "Epoch 27/50 | Val Loss: 7.9168 | Fairness_MAE_Var: 21.3493 | MAE: 7.9168\n",
      "Epoch 28/50 | Val Loss: 7.8500 | Fairness_MAE_Var: 24.1638 | MAE: 7.8500\n",
      "Epoch 29/50 | Val Loss: 7.4833 | Fairness_MAE_Var: 18.8437 | MAE: 7.4833\n",
      "Epoch 30/50 | Val Loss: 7.1887 | Fairness_MAE_Var: 18.5268 | MAE: 7.1887\n",
      "Epoch 31/50 | Val Loss: 6.7426 | Fairness_MAE_Var: 16.6175 | MAE: 6.7426\n",
      "Epoch 32/50 | Val Loss: 5.9067 | Fairness_MAE_Var: 8.7236 | MAE: 5.9067\n",
      "Epoch 33/50 | Val Loss: 5.1905 | Fairness_MAE_Var: 8.1588 | MAE: 5.1905\n",
      "Epoch 34/50 | Val Loss: 4.1729 | Fairness_MAE_Var: 0.6054 | MAE: 4.1729\n",
      "Epoch 35/50 | Val Loss: 3.4358 | Fairness_MAE_Var: 1.6838 | MAE: 3.4358\n",
      "Epoch 36/50 | Val Loss: 3.1361 | Fairness_MAE_Var: 0.6851 | MAE: 3.1361\n",
      "Epoch 37/50 | Val Loss: 3.6912 | Fairness_MAE_Var: 0.9069 | MAE: 3.6912\n",
      "Epoch 38/50 | Val Loss: 3.0234 | Fairness_MAE_Var: 0.5516 | MAE: 3.0234\n",
      "Epoch 39/50 | Val Loss: 3.3407 | Fairness_MAE_Var: 0.7763 | MAE: 3.3407\n",
      "Epoch 40/50 | Val Loss: 3.0381 | Fairness_MAE_Var: 0.6812 | MAE: 3.0381\n",
      "Epoch 41/50 | Val Loss: 3.0412 | Fairness_MAE_Var: 0.5890 | MAE: 3.0412\n",
      "Epoch 42/50 | Val Loss: 2.8436 | Fairness_MAE_Var: 0.5870 | MAE: 2.8436\n",
      "Epoch 43/50 | Val Loss: 2.8952 | Fairness_MAE_Var: 0.4543 | MAE: 2.8952\n",
      "Epoch 44/50 | Val Loss: 2.7000 | Fairness_MAE_Var: 0.5145 | MAE: 2.7000\n",
      "Epoch 45/50 | Val Loss: 2.7724 | Fairness_MAE_Var: 0.4308 | MAE: 2.7724\n",
      "Epoch 46/50 | Val Loss: 2.7361 | Fairness_MAE_Var: 0.5786 | MAE: 2.7361\n",
      "Epoch 47/50 | Val Loss: 3.0866 | Fairness_MAE_Var: 0.2080 | MAE: 3.0866\n",
      "Epoch 48/50 | Val Loss: 2.7181 | Fairness_MAE_Var: 0.6236 | MAE: 2.7181\n",
      "Epoch 49/50 | Val Loss: 2.8124 | Fairness_MAE_Var: 0.4551 | MAE: 2.8124\n",
      "Early stopping at epoch 49\n"
     ]
    }
   ],
   "source": [
    "model = train_model(x_dyn_train, y_train, x_static_train, x_dyn_val, y_val, x_static_val, loss_fn=MAE(),\n",
    "                    log_metrics={\"Fairness_MAE_Var\": GroupFairnessMAEVariance(), \"MAE\": MAE()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19e69a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 2.9408762454986572\n",
      "Test Fairness: 1.771399736404419\n",
      "Test Combined: 2.356137990951538\n"
     ]
    }
   ],
   "source": [
    "group_fairness_metric = GroupFairnessMAEVariance()\n",
    "mae_metric = MAE()\n",
    "mae_group_fairness_metric = MAE_GroupFairness()\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds_test = model(x_dyn_test, x_static_test)\n",
    "    test_mae = mae_metric(preds_test, y_test, x_static_test).item()\n",
    "    test_fairness = group_fairness_metric(preds_test, y_test, x_static_test).item()\n",
    "    test_combined = mae_group_fairness_metric(preds_test, y_test, x_static_test).item()\n",
    "\n",
    "print(\"Test MAE:\", test_mae)\n",
    "print(\"Test Fairness:\", test_fairness)\n",
    "print(\"Test Combined:\", test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b9c011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
