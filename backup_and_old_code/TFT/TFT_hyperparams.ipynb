{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4d2aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "\n",
    "\n",
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import (\n",
    "    optimize_hyperparameters,\n",
    ")\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b9b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:59:34,346] A new study created in memory with name: no-name-bca1444b-efe1-4a80-a218-7fedaadff56f\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2025-11-17 12:32:03,083] Trial 0 finished with value: 1.617850422859192 and parameters: {'gradient_clip_val': 0.0640452871401478, 'hidden_size': 101, 'dropout': 0.19309281742485612, 'hidden_continuous_size': 8, 'attention_head_size': 3, 'learning_rate': 0.0410586091289057}. Best is trial 0 with value: 1.617850422859192.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808668a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b7e8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: False, used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.9978)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "predictions = best_tft.predict(\n",
    "    val_dataloader, return_y=True, trainer_kwargs=dict(accelerator=\"cpu\")\n",
    ")\n",
    "MAE()(predictions.output, predictions.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee41a8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: False, used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions = best_tft.predict(\n",
    "    val_dataloader, mode=\"raw\", return_x=True, trainer_kwargs=dict(accelerator=\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(\n",
    "        raw_predictions.x, raw_predictions.output, idx=idx, add_loss_to_title=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a98af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte metric by which to display\n",
    "predictions = best_tft.predict(\n",
    "    val_dataloader, return_y=True, trainer_kwargs=dict(accelerator=\"cpu\")\n",
    ")\n",
    "mean_losses = SMAPE(reduction=\"none\").loss(predictions.output, predictions.y[0]).mean(1)\n",
    "indices = mean_losses.argsort(descending=True)  # sort losses\n",
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(\n",
    "        raw_predictions.x,\n",
    "        raw_predictions.output,\n",
    "        idx=indices[idx],\n",
    "        add_loss_to_title=SMAPE(quantiles=best_tft.loss.quantiles),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fdf5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_tft.predict(\n",
    "    val_dataloader, return_x=True, trainer_kwargs=dict(accelerator=\"cpu\")\n",
    ")\n",
    "predictions_vs_actuals = best_tft.calculate_prediction_actual_by_variable(\n",
    "    predictions.x, predictions.output\n",
    ")\n",
    "best_tft.plot_prediction_actual_by_variable(predictions_vs_actuals)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
