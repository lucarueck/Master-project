{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942f3257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luca\\miniconda3\\envs\\FairTSBench\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad88dba",
   "metadata": {},
   "source": [
    "# Tutorial 1\n",
    "\n",
    "All tutorial can be accessed here https://github.com/autogluon/fev?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a task from a dataset stored on Hugging Face Hub\n",
    "task = fev.Task(\n",
    "    dataset_path=\"autogluon/chronos_datasets\",\n",
    "    dataset_config=\"ercot\",\n",
    "    horizon=24,\n",
    "    num_windows=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A task consists of multiple rolling evaluation windows\n",
    "for window in task.iter_windows():\n",
    "    print(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8457e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data available as input to the forecasting model\n",
    "past_data, future_data = task.get_window(0).get_input_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb9374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# past data before the forecast horizon.\n",
    "past_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af547b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35701ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# future data that is known at prediction time (item ID, future timestamps, static and known covariates)\n",
    "future_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f61a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def naive_forecast(y: list, horizon: int) -> dict[str, list]:\n",
    "    # Make predictions for a single time series\n",
    "    return {\"predictions\": [y[np.isfinite(y)][-1] for _ in range(horizon)]}\n",
    "\n",
    "predictions_per_window = []\n",
    "for window in task.iter_windows():\n",
    "    past_data, future_data = window.get_input_data()\n",
    "    predictions = [\n",
    "        naive_forecast(ts[task.target], task.horizon) for ts in past_data\n",
    "    ]\n",
    "    predictions_per_window.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_summary = task.evaluation_summary(predictions_per_window, model_name=\"naive\")\n",
    "eval_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05ae106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summaries = pd.read_csv(\"https://raw.githubusercontent.com/autogluon/fev/refs/heads/main/benchmarks/example/results/results.csv\")\n",
    "summaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa214c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation summaries can be provided as dataframes, dicts, JSON or CSV files\n",
    "fev.leaderboard(summaries, baseline_model=\"seasonal_naive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0358bada",
   "metadata": {},
   "source": [
    "# Tutorial 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c7221b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luca\\miniconda3\\envs\\FairTSBench\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import fev\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "datasets.disable_progress_bars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b6ec733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Create a toy dataset with a single time series\n",
    "ts = {\n",
    "    \"id\": \"A\",\n",
    "    \"timestamp\": pd.date_range(\"2025-01-01\", freq=\"D\", periods=10),\n",
    "    \"target\": list(range(10)),\n",
    "}\n",
    "ds = datasets.Dataset.from_list([ts])\n",
    "dataset_path = \"/tmp/toy_dataset.parquet\"\n",
    "ds.to_parquet(dataset_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65950f3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "task = fev.Task(\n",
    "    dataset_path=dataset_path,\n",
    "    horizon=3,\n",
    "    num_windows=2,\n",
    ")\n",
    "\n",
    "# Show the original dataset before any splits (for reference only)\n",
    "full_dataset = task.load_full_dataset()\n",
    "print(full_dataset)\n",
    "print(full_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df497be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how data is split across the 2 evaluation windows\n",
    "for window_index, window in enumerate(task.iter_windows()):\n",
    "    past, future = window.get_input_data()\n",
    "    ground_truth = window.get_ground_truth()\n",
    "    print(f\"Window {window_index} (cutoff={window.cutoff}):\")\n",
    "    print(f\"  Past data:    {past[0]['target']}\")\n",
    "    print(f\"  Ground truth: {ground_truth[0]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e8f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Start evaluation earlier with initial_cutoff\n",
    "task = fev.Task(\n",
    "    dataset_path=dataset_path,\n",
    "    horizon=3,\n",
    "    num_windows=2,\n",
    "    initial_cutoff=-8,\n",
    ")\n",
    "\n",
    "for window_index, window in enumerate(task.iter_windows()):\n",
    "    past, future = window.get_input_data()\n",
    "    ground_truth = window.get_ground_truth()\n",
    "    print(f\"Window {window_index} (cutoff={window.cutoff}):\")\n",
    "    print(f\"  Past data:    {past[0]['target']}\")\n",
    "    print(f\"  Ground truth: {ground_truth[0]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Use pandas timestamp-like strings\n",
    "task = fev.Task(\n",
    "    dataset_path=dataset_path,\n",
    "    horizon=3,\n",
    "    num_windows=2,\n",
    "    initial_cutoff=\"2025-01-05\",\n",
    "    window_step_size=\"2D\",\n",
    ")\n",
    "\n",
    "for window_index, window in enumerate(task.iter_windows()):\n",
    "    past, future = window.get_input_data()\n",
    "    ground_truth = window.get_ground_truth()\n",
    "    print(f\"Window {window_index} (cutoff={window.cutoff}):\")\n",
    "    print(f\"  Past data:    {past[0]['target']}\")\n",
    "    print(f\"  Ground truth: {ground_truth[0]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a3c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = fev.Task(\n",
    "    dataset_path=\"autogluon/chronos_datasets\",\n",
    "    dataset_config=\"m4_hourly\",\n",
    "    horizon=24,\n",
    "    num_windows=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f51efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "task.predictions_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d385cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_forecast(window: fev.EvaluationWindow) -> datasets.Dataset:\n",
    "    assert len(window.target_columns) == 1, \"only univariate forecasting supported\"\n",
    "    predictions: list[dict[str, np.ndarray]] = []\n",
    "    past_data, future_data = window.get_input_data()\n",
    "    for ts in past_data:\n",
    "        y = ts[window.target_columns[0]]\n",
    "        predictions.append(\n",
    "            {\"predictions\": np.array([y[-1] for _ in range(window.horizon)])}\n",
    "        )\n",
    "    return datasets.Dataset.from_list(predictions)\n",
    "\n",
    "window = task.get_window(0)\n",
    "predictions = naive_forecast(window)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87d188",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_per_window = [naive_forecast(window) for window in task.iter_windows()]\n",
    "task.evaluation_summary(predictions_per_window, model_name=\"naive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea506de2",
   "metadata": {},
   "source": [
    "multivariate foecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da30563",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = fev.Task(\n",
    "    dataset_path=\"autogluon/fev_datasets\",\n",
    "    dataset_config=\"ETT_1H\",\n",
    "    horizon=3,\n",
    "    target=[\"OT\", \"LUFL\", \"LULL\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5084f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_data, future_data = task.get_window(0).get_input_data()\n",
    "print(past_data)\n",
    "print(future_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe80cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_forecast_multivariate(window: fev.EvaluationWindow) -> datasets.DatasetDict:\n",
    "    \"\"\"Predicts the last observed value in each multivariate column.\"\"\"\n",
    "    past_data, future_data = window.get_input_data()\n",
    "    predictions = datasets.DatasetDict()\n",
    "    for col in window.target_columns:\n",
    "        predictions_for_column = []\n",
    "        for ts in past_data:\n",
    "            predictions_for_column.append({\"predictions\": [ts[col][-1] for _ in range(window.horizon)]})\n",
    "        predictions[col] = datasets.Dataset.from_list(predictions_for_column)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c2707",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = task.get_window(0)\n",
    "predictions_per_window = naive_forecast_multivariate(window).cast(task.predictions_schema)\n",
    "predictions_per_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in task.target_columns:\n",
    "    print(f\"Predictions for column '{col}'\")\n",
    "    print(f\"\\t{predictions_per_window[col].to_list()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d4d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "task.evaluation_summary([predictions_per_window], model_name=\"naive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27efe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = fev.Task(\n",
    "    dataset_path=\"autogluon/fev_datasets\",\n",
    "    dataset_config=\"ETT_1H\",\n",
    "    horizon=3,\n",
    "    generate_univariate_targets_from=[\"OT\", \"LUFL\", \"LULL\"],\n",
    "    target=\"target\",  # new name for the target columns ['OT', 'LUFL', 'LULL'] after splitting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4048cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_data, future_data = task.get_window(0).get_input_data()\n",
    "print(past_data)\n",
    "print(future_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb83c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_data[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80986d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_forecast_univariate(window: fev.EvaluationWindow) -> datasets.Dataset:\n",
    "    \"\"\"Predicts the last observed value.\"\"\"\n",
    "    past_data, future_data = window.get_input_data()\n",
    "    predictions = []\n",
    "    for ts in past_data:\n",
    "        predictions.append({\"predictions\": [ts[window.target_columns[0]][-1] for _ in range(window.horizon)]})\n",
    "    return datasets.Dataset.from_list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fbd491",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_per_window = []\n",
    "for window in task.iter_windows():\n",
    "    predictions_per_window.append(naive_forecast_univariate(window))\n",
    "task.evaluation_summary(predictions_per_window, model_name=\"naive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c18191e",
   "metadata": {},
   "source": [
    "Evaluating on a benchmark (see tutorial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FairTSBench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
